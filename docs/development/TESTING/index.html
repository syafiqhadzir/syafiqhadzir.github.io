<h1>Testing Guide</h1>
<blockquote>
<p><strong>Comprehensive guide to testing strategies, tools, and requirements</strong></p>
</blockquote>
<p><a href="../../README.md">üè† Home</a> / <a href="../README.md">üìö Docs</a> / <a href="README.md">Development</a> / Testing</p>
<h2>Table of Contents</h2>
<ul>
<li><a href="#testing-philosophy">Testing Philosophy</a></li>
<li><a href="#test-types">Test Types</a></li>
<li><a href="#unit-testing-vitest">Unit Testing (Vitest)</a></li>
<li><a href="#e2e-testing-cypress">E2E Testing (Cypress)</a></li>
<li><a href="#performance-testing-lighthouse">Performance Testing (Lighthouse)</a></li>
<li><a href="#coverage-requirements">Coverage Requirements</a></li>
<li><a href="#running-tests">Running Tests</a></li>
<li><a href="#writing-tests">Writing Tests</a></li>
<li><a href="#cicd-integration">CI/CD Integration</a></li>
<li><a href="#troubleshooting">Troubleshooting</a></li>
</ul>
<hr>
<h2>Testing Philosophy</h2>
<p>This project enforces strict quality gates with comprehensive test coverage:</p>
<ul>
<li><strong>Zero-defect mindset</strong> - All code must be tested before merge</li>
<li><strong>Fast feedback</strong> - Unit tests run in &lt; 10 seconds</li>
<li><strong>Real-world validation</strong> - E2E tests verify user workflows</li>
<li><strong>Performance accountability</strong> - Lighthouse enforces 100/100 scores</li>
</ul>
<hr>
<h2>Test Types</h2>
<h3>Unit Tests</h3>
<ul>
<li><strong>Tool:</strong> Vitest</li>
<li><strong>Coverage:</strong> 80% minimum (statements, branches, functions, lines)</li>
<li><strong>Speed:</strong> &lt; 10 seconds for full suite</li>
<li><strong>Purpose:</strong> Test individual functions, modules, and transforms</li>
</ul>
<h3>End-to-End (E2E) Tests</h3>
<ul>
<li><strong>Tool:</strong> Cypress</li>
<li><strong>Browser:</strong> Chrome (headless in CI)</li>
<li><strong>Purpose:</strong> Test complete user workflows and accessibility</li>
</ul>
<h3>Performance Tests</h3>
<ul>
<li><strong>Tool:</strong> Lighthouse CI</li>
<li><strong>Threshold:</strong> 100/100 for all metrics</li>
<li><strong>Purpose:</strong> Enforce performance budgets and best practices</li>
</ul>
<h3>Integration Tests</h3>
<ul>
<li><strong>Approach:</strong> Build validation</li>
<li><strong>Purpose:</strong> Ensure AMP compliance and output correctness</li>
</ul>
<hr>
<h2>Unit Testing (Vitest)</h2>
<h3>Running Unit Tests</h3>
<pre><code class="language-bash"># Run all unit tests
npm run test:unit

# Run with coverage
npm run test:unit:coverage

# Watch mode (interactive)
npm run test:unit:watch
</code></pre>
<h3>Test Structure</h3>
<pre><code class="language-typescript">// test/filters/dateFormat.test.ts
import { describe, it, expect } from 'vitest';
import { dateFormat } from '../../src/filters/dateFormat';

describe('dateFormat filter', () =&gt; {
  it('formats dates in YYYY-MM-DD format', () =&gt; {
    const date = new Date('2025-12-23');
    expect(dateFormat(date)).toBe('2025-12-23');
  });

  it('handles invalid dates gracefully', () =&gt; {
    expect(dateFormat(new Date('invalid'))).toBe('Invalid Date');
  });
});
</code></pre>
<h3>What to Test</h3>
<p>‚úÖ <strong>Test:</strong></p>
<ul>
<li>Pure functions with clear inputs/outputs</li>
<li>Edge cases (null, undefined, empty strings)</li>
<li>Error handling</li>
<li>Public API surfaces</li>
</ul>
<p>‚ùå <strong>Don't Test:</strong></p>
<ul>
<li>Third-party library internals</li>
<li>Simple getters/setters</li>
<li>Trivial utility wrappers</li>
</ul>
<h3>Coverage Configuration</h3>
<p>Located in <code>vitest.config.ts</code>:</p>
<pre><code class="language-typescript">coverage: {
  provider: 'v8',
  reporter: ['text', 'lcov', 'html'],
  thresholds: {
    statements: 80,
    branches: 80,
    functions: 80,
    lines: 80,
  },
}
</code></pre>
<h3>Excluded from Coverage</h3>
<ul>
<li>Test files (<code>.test.ts</code>, <code>.spec.ts</code>)</li>
<li>Configuration files (<code>vitest.config.ts</code>, <code>eleventy.config.js</code>)</li>
<li>Type definitions (<code>.d.ts</code>)</li>
<li>Build integration modules (<code>src/lib/</code>)</li>
</ul>
<hr>
<h2>E2E Testing (Cypress)</h2>
<h3>Running E2E Tests</h3>
<pre><code class="language-bash"># Run all E2E tests (headless)
npm run test:e2e

# Run specific test suite
npm run test:smoke    # Smoke tests only
npm run test:a11y     # Accessibility tests only

# Interactive mode (Cypress UI)
npm run test:e2e:open
</code></pre>
<h3>Test Structure</h3>
<pre><code class="language-typescript">// cypress/e2e/smoke.cy.ts
describe('Homepage', () =&gt; {
  beforeEach(() =&gt; {
    cy.visit('/');
  });

  it('loads successfully', () =&gt; {
    cy.get('h1').should('be.visible');
  });

  it('has valid AMP HTML', () =&gt; {
    cy.get('html').should('have.attr', 'amp');
  });
});
</code></pre>
<h3>Accessibility Testing</h3>
<p>Using <code>cypress-axe</code> for automated a11y checks:</p>
<pre><code class="language-typescript">// cypress/e2e/a11y.cy.ts
import 'cypress-axe';

describe('Accessibility', () =&gt; {
  beforeEach(() =&gt; {
    cy.visit('/');
    cy.injectAxe();
  });

  it('has no detectable a11y violations (WCAG AA)', () =&gt; {
    cy.checkA11y(null, {
      runOnly: {
        type: 'tag',
        values: ['wcag2a', 'wcag2aa'],
      },
    });
  });
});
</code></pre>
<h3>E2E Best Practices</h3>
<p>‚úÖ <strong>Do:</strong></p>
<ul>
<li>Use <code>data-testid</code> attributes for selectors</li>
<li>Test user workflows, not implementation</li>
<li>Keep tests independent (no shared state)</li>
<li>Use realistic test data</li>
</ul>
<p>‚ùå <strong>Don't:</strong></p>
<ul>
<li>Test third-party components</li>
<li>Rely on brittle CSS selectors</li>
<li>Create dependencies between tests</li>
<li>Mock API calls (test real integration)</li>
</ul>
<hr>
<h2>Performance Testing (Lighthouse)</h2>
<h3>Running Lighthouse</h3>
<pre><code class="language-bash"># Local audit (requires Chrome)
npm run perf:local

# CI audit (uses LHCI server)
npm run perf:ci
</code></pre>
<h3>Lighthouse Configuration</h3>
<p>Located in <code>lighthouserc.cjs</code>:</p>
<pre><code class="language-javascript">module.exports = {
  ci: {
    assert: {
      preset: 'lighthouse:recommended',
      assertions: {
        'categories:performance': ['error', { minScore: 1 }],
        'categories:accessibility': ['error', { minScore: 1 }],
        'categories:best-practices': ['error', { minScore: 1 }],
        'categories:seo': ['error', { minScore: 1 }],
      },
    },
  },
};
</code></pre>
<h3>Performance Budget</h3>
<p>Defined in <code>perf-budget.json</code>:</p>
<pre><code class="language-json">{
  &quot;resourceSizes&quot;: [
    {
      &quot;resourceType&quot;: &quot;script&quot;,
      &quot;budget&quot;: 50
    },
    {
      &quot;resourceType&quot;: &quot;stylesheet&quot;,
      &quot;budget&quot;: 30
    }
  ]
}
</code></pre>
<hr>
<h2>Coverage Requirements</h2>
<h3>Minimum Thresholds</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Threshold</th>
<th>Enforced By</th>
</tr>
</thead>
<tbody>
<tr>
<td>Statements</td>
<td>80%</td>
<td>Vitest</td>
</tr>
<tr>
<td>Branches</td>
<td>80%</td>
<td>Vitest</td>
</tr>
<tr>
<td>Functions</td>
<td>80%</td>
<td>Vitest</td>
</tr>
<tr>
<td>Lines</td>
<td>80%</td>
<td>Vitest</td>
</tr>
<tr>
<td>New Code Coverage</td>
<td>80%</td>
<td>SonarCloud</td>
</tr>
</tbody>
</table>
<h3>Viewing Coverage Reports</h3>
<pre><code class="language-bash"># Generate coverage report
npm run test:unit:coverage

# Open HTML report in browser
open coverage/index.html        # macOS
start coverage/index.html       # Windows
xdg-open coverage/index.html    # Linux
</code></pre>
<h3>LCOV Report</h3>
<p>Coverage data is exported to <code>coverage/lcov.info</code> for SonarCloud ingestion.</p>
<p>See <a href="SONARCLOUD.md">SonarCloud Observability Guide</a> for debugging coverage gaps.</p>
<hr>
<h2>Running Tests</h2>
<h3>Quick Test Commands</h3>
<pre><code class="language-bash"># Run everything (unit + E2E)
npm test

# Unit tests only
npm run test:unit

# E2E tests only
npm run test:e2e

# Specific E2E suite
npm run test:smoke
npm run test:a11y

# With coverage
npm run test:unit:coverage

# Clean test artifacts
npm run test:clean
</code></pre>
<h3>CI Contexts</h3>
<p>The CI pipeline runs different test suites depending on context:</p>
<p><strong>PR Validation:</strong></p>
<ul>
<li>‚úÖ Unit tests</li>
<li>‚ùå E2E tests (skipped for speed)</li>
</ul>
<p><strong>Nightly Quality:</strong></p>
<ul>
<li>‚úÖ Unit tests</li>
<li>‚úÖ E2E tests (smoke + a11y)</li>
<li>‚úÖ SonarCloud scan</li>
</ul>
<p><strong>Deployment:</strong></p>
<ul>
<li>‚úÖ Full build</li>
<li>‚úÖ Lighthouse CI</li>
<li>‚ùå Unit/E2E (validated in previous steps)</li>
</ul>
<hr>
<h2>Writing Tests</h2>
<h3>File Naming Conventions</h3>
<pre><code>test/
‚îú‚îÄ‚îÄ filters/
‚îÇ   ‚îî‚îÄ‚îÄ dateFormat.test.ts     # Unit tests for src/filters/dateFormat.ts
‚îú‚îÄ‚îÄ transforms/
‚îÇ   ‚îî‚îÄ‚îÄ cssGuard.test.ts       # Unit tests for src/transforms/cssGuard.ts
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ housekeeping.test.ts   # Unit tests for scripts/housekeeping.ts

cypress/
‚îî‚îÄ‚îÄ e2e/
    ‚îú‚îÄ‚îÄ smoke.cy.ts            # Smoke tests
    ‚îú‚îÄ‚îÄ a11y.cy.ts             # Accessibility tests
    ‚îî‚îÄ‚îÄ darkmode.cy.ts         # Feature-specific tests
</code></pre>
<h3>Test Patterns</h3>
<h4>Arrange-Act-Assert (AAA)</h4>
<pre><code class="language-typescript">it('should format date correctly', () =&gt; {
  // Arrange
  const input = new Date('2025-12-23');

  // Act
  const result = dateFormat(input);

  // Assert
  expect(result).toBe('2025-12-23');
});
</code></pre>
<h4>Given-When-Then (BDD)</h4>
<pre><code class="language-typescript">describe('Date Formatter', () =&gt; {
  describe('given a valid date', () =&gt; {
    it('should return formatted string when called', () =&gt; {
      const date = new Date('2025-12-23');
      expect(dateFormat(date)).toBe('2025-12-23');
    });
  });

  describe('given an invalid date', () =&gt; {
    it('should return error message when called', () =&gt; {
      expect(dateFormat(new Date('invalid'))).toBe('Invalid Date');
    });
  });
});
</code></pre>
<h3>Mocking</h3>
<pre><code class="language-typescript">import { vi, describe, it, expect, beforeEach } from 'vitest';

describe('Logger', () =&gt; {
  beforeEach(() =&gt; {
    vi.clearAllMocks();
  });

  it('should call console.log', () =&gt; {
    const logSpy = vi.spyOn(console, 'log');
    logger.info('test message');
    expect(logSpy).toHaveBeenCalledWith('test message');
  });
});
</code></pre>
<hr>
<h2>CI/CD Integration</h2>
<h3>Workflow Triggers</h3>
<p><strong><code>pr-validation.yml</code></strong></p>
<ul>
<li>Runs on: Pull requests to <code>main</code></li>
<li>Tests: Unit tests only</li>
<li>Duration: ~3 minutes</li>
</ul>
<p><strong><code>nightly-quality.yml</code></strong></p>
<ul>
<li>Runs on: Daily at midnight UTC, manual dispatch</li>
<li>Tests: Unit + E2E (smoke, a11y) + SonarCloud</li>
<li>Duration: ~10 minutes</li>
</ul>
<p><strong><code>deploy.yml</code></strong></p>
<ul>
<li>Runs on: Version tags (<code>v*</code>)</li>
<li>Tests: Lighthouse CI</li>
<li>Duration: ~5 minutes</li>
</ul>
<h3>Debugging Test Failures in CI</h3>
<ol>
<li>
<p><strong>Check workflow logs:</strong></p>
<ul>
<li>Go to Actions tab</li>
<li>Click failed run</li>
<li>Expand failed step</li>
</ul>
</li>
<li>
<p><strong>Download test artifacts:</strong></p>
<ul>
<li>Scroll to bottom of run page</li>
<li>Download <code>cypress-screenshots</code> (if E2E failed)</li>
<li>Download <code>sonarcloud-diagnostics</code> (if Sonar failed)</li>
</ul>
</li>
<li>
<p><strong>Reproduce locally:</strong></p>
<pre><code class="language-bash"># Run exact same command from CI
npm run test:e2e:ci
</code></pre>
</li>
</ol>
<hr>
<h2>Troubleshooting</h2>
<h3>Unit Test Failures</h3>
<p><strong>Issue:</strong> Tests pass locally but fail in CI</p>
<pre><code class="language-bash"># Ensure clean install
rm -rf node_modules package-lock.json
npm ci
npm run test:unit
</code></pre>
<p><strong>Issue:</strong> Coverage threshold not met</p>
<pre><code class="language-bash"># Generate coverage report
npm run test:unit:coverage

# Open HTML report to see uncovered lines
open coverage/index.html
</code></pre>
<h3>E2E Test Failures</h3>
<p><strong>Issue:</strong> Cypress can't connect to server</p>
<pre><code class="language-bash"># Ensure build succeeded
npm run build

# Start server in separate terminal
npm run serve

# Run E2E tests
npm run test:e2e
</code></pre>
<p><strong>Issue:</strong> Accessibility violations</p>
<p>View Cypress console output for specific violations:</p>
<ul>
<li>Selector of failing element</li>
<li>WCAG guideline violated</li>
<li>Severity level</li>
</ul>
<h3>Performance Test Failures</h3>
<p><strong>Issue:</strong> Lighthouse score &lt; 100</p>
<pre><code class="language-bash"># Run local audit for detailed report
npm run perf:local

# Check specific audit failures
# Common issues: unused CSS, large images, blocking scripts
</code></pre>
<hr>
<h2>Related Documentation</h2>
<ul>
<li><strong><a href="README.md">Development Guide</a></strong> - Development setup and workflows</li>
<li><strong><a href="SONARCLOUD.md">SonarCloud Observability</a></strong> - Coverage debugging and quality gates</li>
<li><strong><a href="../../scripts/README.md">Scripts README</a></strong> - CLI test utilities</li>
</ul>
<hr>
<h2>External Resources</h2>
<ul>
<li><a href="https://vitest.dev/">Vitest Documentation</a></li>
<li><a href="https://docs.cypress.io/guides/references/best-practices">Cypress Best Practices</a></li>
<li><a href="https://web.dev/performance-budgets-101/">Lighthouse Performance Budgets</a></li>
<li><a href="https://www.w3.org/WAI/WCAG21/quickref/">WCAG 2.1 Guidelines</a></li>
</ul>
<hr>
<p><strong>Last Updated:</strong> 2025-12-23</p>
<p><a href="#testing-guide">‚Üë Back to Top</a></p>
